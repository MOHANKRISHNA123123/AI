import heapq

class PuzzleState:
    def __init__(self, board, parent=None, move="Initial", depth=0):
        self.board = board
        self.parent = parent
        self.move = move
        self.depth = depth
        self.goal = [1, 2, 3, 4, 5, 6, 7, 8, 0]  # Goal state configuration
    
    def __lt__(self, other):
        return (self.depth + self.manhattan()) < (other.depth + other.manhattan())
    
    def __eq__(self, other):
        return self.board == other.board
    
    def __hash__(self):
        return hash(str(self.board))
    
    def __str__(self):
        return '\n'.join([str(self.board[i:i+3]) for i in range(0, len(self.board), 3)])
    
    def manhattan(self):
        # Calculate the Manhattan distance heuristic
        distance = 0
        for i in range(1, 9):
            current_row, current_col = self.get_location(self.board.index(i))
            goal_row, goal_col = self.get_location(self.goal.index(i))
            distance += abs(current_row - goal_row) + abs(current_col - goal_col)
        return distance
    
    def get_location(self, index):
        # Get row and column of the index in the board
        return (index // 3, index % 3)
    
    def get_possible_moves(self):
        # Find possible moves (up, down, left, right)
        moves = []
        empty_index = self.board.index(0)
        row, col = self.get_location(empty_index)
        
        if row > 0:
            moves.append('Up')
        if row < 2:
            moves.append('Down')
        if col > 0:
            moves.append('Left')
        if col < 2:
            moves.append('Right')
        
        return moves
    
    def generate_moves(self):
        # Generate new states based on possible moves
        empty_index = self.board.index(0)
        row, col = self.get_location(empty_index)
        possible_moves = self.get_possible_moves()
        states = []
        
        for move in possible_moves:
            new_board = self.board[:]
            
            if move == 'Up':
                new_board[empty_index], new_board[empty_index - 3] = new_board[empty_index - 3], new_board[empty_index]
            elif move == 'Down':
                new_board[empty_index], new_board[empty_index + 3] = new_board[empty_index + 3], new_board[empty_index]
            elif move == 'Left':
                new_board[empty_index], new_board[empty_index - 1] = new_board[empty_index - 1], new_board[empty_index]
            elif move == 'Right':
                new_board[empty_index], new_board[empty_index + 1] = new_board[empty_index + 1], new_board[empty_index]
            
            states.append(PuzzleState(new_board, self, move, self.depth + 1))
        
        return states
    
    def is_goal_state(self):
        return self.board == self.goal
    
    def traceback_path(self):
        # Trace back from the goal state to the initial state
        current_state = self
        path = []
        while current_state:
            path.append(current_state)
            current_state = current_state.parent
        path.reverse()
        return path
    
def solve_puzzle(initial_state):
    # Priority queue for A* search
    open_list = []
    closed_list = set()
    
    heapq.heappush(open_list, initial_state)
    
    while open_list:
        current_state = heapq.heappop(open_list)
        
        if current_state.is_goal_state():
            return current_state.traceback_path()
        
        closed_list.add(current_state)
        
        for move in current_state.generate_moves():
            if move not in closed_list:
                heapq.heappush(open_list, move)
    
    return None

# Example usage:
initial_board = [1, 2, 3, 4, 5, 6, 7, 0, 8]  # Example initial board configuration
initial_state = PuzzleState(initial_board)

solution_path = solve_puzzle(initial_state)

if solution_path:
    print(f"Solution found in {len(solution_path) - 1} moves:")
    for i, state in enumerate(solution_path):
        print(f"Move {i}: {state.move}")
        print(state)
        print()
else:
    print("No solution found.")
